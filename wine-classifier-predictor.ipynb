{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows the classification of the wine quality (low, medium, high) and wine type (red or white) based on the various predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         6497 non-null   float64\n",
      " 1   volatile acidity      6497 non-null   float64\n",
      " 2   citric acid           6497 non-null   float64\n",
      " 3   residual sugar        6497 non-null   float64\n",
      " 4   chlorides             6497 non-null   float64\n",
      " 5   free sulfur dioxide   6497 non-null   float64\n",
      " 6   total sulfur dioxide  6497 non-null   float64\n",
      " 7   density               6497 non-null   float64\n",
      " 8   pH                    6497 non-null   float64\n",
      " 9   sulphates             6497 non-null   float64\n",
      " 10  alcohol               6497 non-null   float64\n",
      " 11  quality               6497 non-null   int64  \n",
      " 12  winetype              6497 non-null   object \n",
      " 13  wine-quality          6497 non-null   object \n",
      "dtypes: float64(11), int64(1), object(2)\n",
      "memory usage: 710.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"all_wines.csv\")\n",
    "# print(df.head(2))\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   fixed acidity         6497 non-null   float64 \n",
      " 1   volatile acidity      6497 non-null   float64 \n",
      " 2   citric acid           6497 non-null   float64 \n",
      " 3   residual sugar        6497 non-null   float64 \n",
      " 4   chlorides             6497 non-null   float64 \n",
      " 5   free sulfur dioxide   6497 non-null   float64 \n",
      " 6   total sulfur dioxide  6497 non-null   float64 \n",
      " 7   density               6497 non-null   float64 \n",
      " 8   pH                    6497 non-null   float64 \n",
      " 9   sulphates             6497 non-null   float64 \n",
      " 10  alcohol               6497 non-null   float64 \n",
      " 11  quality               6497 non-null   int64   \n",
      " 12  winetype              6497 non-null   object  \n",
      " 13  wine-quality          6497 non-null   category\n",
      "dtypes: category(1), float64(11), int64(1), object(1)\n",
      "memory usage: 666.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# change wine quality to categorical variable\n",
    "df['wine-quality'] = pd.Categorical(df['wine-quality'], categories=['low','medium', 'high'])\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            6.1              0.22         0.38             2.8      0.144   \n",
      "1            5.7              0.29         0.16             7.9      0.044   \n",
      "2            6.9              0.26         0.27             4.2      0.031   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 12.0                  65.0  0.99080  2.95       0.64   \n",
      "1                 48.0                 197.0  0.99512  3.21       0.36   \n",
      "2                 20.0                  80.0  0.99089  3.12       0.39   \n",
      "\n",
      "   alcohol  \n",
      "0     11.4  \n",
      "1      9.4  \n",
      "2     11.5  \n"
     ]
    }
   ],
   "source": [
    "# select only the features\n",
    "allwine_features = df.iloc[:,:-3]\n",
    "print(allwine_features.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_wine = df['winetype']\n",
    "quality_of_wine = df['wine-quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we attempt to predict the tpe of wine and the quality of wine using the various classifier models. The best model will be selected using the GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(allwine_features, type_of_wine, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with scaler and classifier\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', None)\n",
    "])\n",
    "# Define parameter grid for each classifier\n",
    "param_grid = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__max_iter':[150,300,500,1000]\n",
    "    },\n",
    "    {\n",
    "        'classifier': [SVC()],\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': [10, 50, 100, 200]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;classifier&#x27;, None)]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: [LogisticRegression()],\n",
       "                          &#x27;classifier__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;classifier__max_iter&#x27;: [150, 300, 500, 1000]},\n",
       "                         {&#x27;classifier&#x27;: [SVC(C=10, gamma=0.01)],\n",
       "                          &#x27;classifier__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;classifier__gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "                         {&#x27;classifier&#x27;: [RandomForestClassifier()],\n",
       "                          &#x27;classifier__n_estimators&#x27;: [10, 50, 100, 200]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;classifier&#x27;, None)]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: [LogisticRegression()],\n",
       "                          &#x27;classifier__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;classifier__max_iter&#x27;: [150, 300, 500, 1000]},\n",
       "                         {&#x27;classifier&#x27;: [SVC(C=10, gamma=0.01)],\n",
       "                          &#x27;classifier__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;classifier__gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "                         {&#x27;classifier&#x27;: [RandomForestClassifier()],\n",
       "                          &#x27;classifier__n_estimators&#x27;: [10, 50, 100, 200]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, None)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()],\n",
       "                          'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__max_iter': [150, 300, 500, 1000]},\n",
       "                         {'classifier': [SVC(C=10, gamma=0.01)],\n",
       "                          'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 200]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for the best classifier\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Classifier: SVC(C=10, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Get the best classifier\n",
    "best_classifier = grid_search.best_estimator_\n",
    "print(\"Best Classifier:\", best_classifier.named_steps['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best classifier\n",
    "y_pred = best_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    red-wine       0.99      0.98      0.99       313\n",
      "  white-wine       0.99      1.00      1.00       987\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classifier:  Logistic Regression\n",
      "**********\n",
      "Accuracy of model Logistic Regression: 0.9930769230769231\n",
      "Classification Report for:  Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    red-wine       0.99      0.98      0.99       313\n",
      "  white-wine       0.99      1.00      1.00       987\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n",
      "********\n",
      "Cross validation report for:  Logistic Regression\n",
      "scores: [0.99038462 0.99038462 0.99422522 0.99518768 0.99518768], Average accuracy: 0.9930739616495151\n",
      "\n",
      " Classifier:  SVM\n",
      "**********\n",
      "Accuracy of model SVM: 0.9946153846153846\n",
      "Classification Report for:  SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    red-wine       0.99      0.98      0.99       313\n",
      "  white-wine       0.99      1.00      1.00       987\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n",
      "********\n",
      "Cross validation report for:  SVM\n",
      "scores: [0.99615385 0.99134615 0.99807507 0.99518768 0.99807507], Average accuracy: 0.9957675649663138\n",
      "\n",
      " Classifier:  Random Forest\n",
      "**********\n",
      "Accuracy of model Random Forest: 0.9946153846153846\n",
      "Classification Report for:  Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    red-wine       0.99      0.98      0.99       313\n",
      "  white-wine       0.99      1.00      1.00       987\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n",
      "********\n",
      "Cross validation report for:  Random Forest\n",
      "scores: [0.99519231 0.99326923 0.99518768 0.99518768 0.99711261], Average accuracy: 0.9951899015325388\n"
     ]
    }
   ],
   "source": [
    "#Next, we print the accuracy, confusion matrix, and cross validation score for all the classifiers.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifiers = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('SVM', SVC()),\n",
    "    ('Random Forest', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    print(\"\\n Classifier: \",name)\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    preds = clf.predict(X_test_scaled)\n",
    "\n",
    "    cvscores = cross_val_score(clf, X_train_scaled,y_train,cv=5,scoring='accuracy')\n",
    "\n",
    "    print(\"**********\")\n",
    "    print(f\"Accuracy of model {name}: {accuracy_score(y_test,preds)}\")\n",
    "    print(\"Classification Report for: \", name)\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    print(\"********\")\n",
    "    print(\"Cross validation report for: \", name)\n",
    "    print(f\"scores: {cvscores}, Average accuracy: {np.mean(cvscores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we do the same for wine quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(allwine_features, quality_of_wine, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;classifier&#x27;, None)]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: [LogisticRegression()],\n",
       "                          &#x27;classifier__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;classifier__max_iter&#x27;: [150, 300, 500, 1000]},\n",
       "                         {&#x27;classifier&#x27;: [SVC(C=10, gamma=0.01)],\n",
       "                          &#x27;classifier__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;classifier__gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "                         {&#x27;classifier&#x27;: [RandomForestClassifier()],\n",
       "                          &#x27;classifier__n_estimators&#x27;: [10, 50, 100, 200]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;classifier&#x27;, None)]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: [LogisticRegression()],\n",
       "                          &#x27;classifier__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;classifier__max_iter&#x27;: [150, 300, 500, 1000]},\n",
       "                         {&#x27;classifier&#x27;: [SVC(C=10, gamma=0.01)],\n",
       "                          &#x27;classifier__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;classifier__gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "                         {&#x27;classifier&#x27;: [RandomForestClassifier()],\n",
       "                          &#x27;classifier__n_estimators&#x27;: [10, 50, 100, 200]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, None)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()],\n",
       "                          'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__max_iter': [150, 300, 500, 1000]},\n",
       "                         {'classifier': [SVC(C=10, gamma=0.01)],\n",
       "                          'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 200]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Classifier: RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "best_classifier = grid_search.best_estimator_\n",
    "print(\"Best Classifier:\", best_classifier.named_steps['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best classifier\n",
    "y_pred = best_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.94      0.35      0.51        43\n",
      "         low       0.79      0.72      0.75       464\n",
      "      medium       0.82      0.89      0.85       793\n",
      "\n",
      "    accuracy                           0.81      1300\n",
      "   macro avg       0.85      0.65      0.70      1300\n",
      "weighted avg       0.81      0.81      0.80      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classifier:  Logistic Regression\n",
      "**********\n",
      "Accuracy of model Logistic Regression: 0.7238461538461538\n",
      "Classification Report for:  Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00        43\n",
      "         low       0.68      0.58      0.63       464\n",
      "      medium       0.74      0.84      0.79       793\n",
      "\n",
      "    accuracy                           0.72      1300\n",
      "   macro avg       0.48      0.48      0.47      1300\n",
      "weighted avg       0.70      0.72      0.71      1300\n",
      "\n",
      "********\n",
      "Cross validation report for:  Logistic Regression\n",
      "scores: [0.71153846 0.69903846 0.70837344 0.71799808 0.70644851], Average accuracy: 0.7086793884652403\n",
      "\n",
      " Classifier:  SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhira\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dhira\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dhira\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Accuracy of model SVM: 0.75\n",
      "Classification Report for:  SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00        43\n",
      "         low       0.72      0.64      0.68       464\n",
      "      medium       0.76      0.85      0.81       793\n",
      "\n",
      "    accuracy                           0.75      1300\n",
      "   macro avg       0.49      0.50      0.50      1300\n",
      "weighted avg       0.72      0.75      0.73      1300\n",
      "\n",
      "********\n",
      "Cross validation report for:  SVM\n",
      "scores: [0.7375     0.73942308 0.74013474 0.74494706 0.73917228], Average accuracy: 0.7402354334789368\n",
      "\n",
      " Classifier:  Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhira\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dhira\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dhira\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Accuracy of model Random Forest: 0.806923076923077\n",
      "Classification Report for:  Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.93      0.33      0.48        43\n",
      "         low       0.78      0.73      0.75       464\n",
      "      medium       0.82      0.88      0.85       793\n",
      "\n",
      "    accuracy                           0.81      1300\n",
      "   macro avg       0.84      0.64      0.69      1300\n",
      "weighted avg       0.81      0.81      0.80      1300\n",
      "\n",
      "********\n",
      "Cross validation report for:  Random Forest\n",
      "scores: [0.80192308 0.81442308 0.79307026 0.80076997 0.79307026], Average accuracy: 0.8006513289405494\n"
     ]
    }
   ],
   "source": [
    "for name, clf in classifiers:\n",
    "    print(\"\\n Classifier: \",name)\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    preds = clf.predict(X_test_scaled)\n",
    "\n",
    "    cvscores = cross_val_score(clf, X_train_scaled,y_train,cv=5,scoring='accuracy')\n",
    "\n",
    "    print(\"**********\")\n",
    "    print(f\"Accuracy of model {name}: {accuracy_score(y_test,preds)}\")\n",
    "    print(\"Classification Report for: \", name)\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    print(\"********\")\n",
    "    print(\"Cross validation report for: \", name)\n",
    "    print(f\"scores: {cvscores}, Average accuracy: {np.mean(cvscores)}\")b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
